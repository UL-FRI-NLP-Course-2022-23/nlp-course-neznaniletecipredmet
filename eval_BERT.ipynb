{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hm3lCq7uGM1a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (TFBertForSequenceClassification, \n",
    "                          BertTokenizer)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvkQrdEbGM91"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('')\n",
    "\n",
    "# Transform positive/negative values to 1/0s\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data['sentiment'] = label_encoder.fit_transform(data['sentiment'])\n",
    "\n",
    "X = (np.array(data['review']))\n",
    "y = (np.array(data['sentiment']))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQfWAE_MTJxk"
   },
   "outputs": [],
   "source": [
    "pad_token=0\n",
    "pad_token_segment_id=0\n",
    "max_length=128\n",
    "\n",
    "def convert_to_input(reviews):\n",
    "  input_ids,attention_masks,token_type_ids=[],[],[]\n",
    "  \n",
    "  for x in tqdm(reviews,position=0, leave=True):\n",
    "    inputs = bert_tokenizer.encode_plus(x,add_special_tokens=True, max_length=max_length)\n",
    "    \n",
    "    i, t = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "    m = [1] * len(i)\n",
    "\n",
    "    padding_length = max_length - len(i)\n",
    "\n",
    "    i = i + ([pad_token] * padding_length)\n",
    "    m = m + ([0] * padding_length)\n",
    "    t = t + ([pad_token_segment_id] * padding_length)\n",
    "    \n",
    "    input_ids.append(i)\n",
    "    attention_masks.append(m)\n",
    "    token_type_ids.append(t)\n",
    "  \n",
    "  return [np.asarray(input_ids), \n",
    "            np.asarray(attention_masks), \n",
    "            np.asarray(token_type_ids)]\n",
    "\n",
    "def example_to_features(input_ids,attention_masks,token_type_ids,y):\n",
    "  return {\"input_ids\": input_ids,\n",
    "          \"attention_mask\": attention_masks,\n",
    "          \"token_type_ids\": token_type_ids},y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "kitY8ZX4mHwe",
    "outputId": "bfa8d76f-2c63-4860-b789-7c054a43f6bf"
   },
   "outputs": [],
   "source": [
    "X_test_input=convert_to_input(X_test)\n",
    "X_train_input=convert_to_input(X_train)\n",
    "X_val_input=convert_to_input(X_val)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_input[0],X_train_input[1],X_train_input[2],y_train)).map(example_to_features).shuffle(100).batch(12).repeat(5)\n",
    "val_ds=tf.data.Dataset.from_tensor_slices((X_val_input[0],X_val_input[1],X_val_input[2],y_val)).map(example_to_features).batch(12)\n",
    "test_ds=tf.data.Dataset.from_tensor_slices((X_test_input[0],X_test_input[1],X_test_input[2],y_test)).map(example_to_features).batch(12)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "print(\"Fine-tuning BERT on IMDB dataset\")\n",
    "bert_history = bert_model.fit(train_ds, epochs=3, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_true = test_ds.unbatch()\n",
    "results_true = np.asarray([element[1].numpy() for element in results_true])\n",
    "\n",
    "results = bert_model.predict(test_ds)\n",
    "\n",
    "results_predicted = np.argmax(results.logits, axis=1)\n",
    "\n",
    "print(f\"F1 score: {f1_score(results_true, results_predicted)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(results_true, results_predicted)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Text Classification IMDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
